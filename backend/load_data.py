from sqlmodel import Session, create_engine, select
from main import Hospital, sqlite_url
import pandas as pd
import os

# Ensure the database exists by importing the engine
engine = create_engine(sqlite_url)

def load_hospitals_from_csv(csv_path: str):
    if not os.path.exists(csv_path):
        print(f"Error: {csv_path} not found.")
        return

    df = pd.read_csv(csv_path)
    # Map CSV columns to SQL Model (Assuming columns match or are mapped)
    # For now, we simulate loading more data
    
    with Session(engine) as session:
        for index, row in df.iterrows():
            # Basic validation/mapping
            hosp = Hospital(
                name_es=row['hospital'],
                name_en=row['hospital'], # Fallback
                city=row['city'],
                lat=40.0, # Dummy coords for now
                lng=-3.0,
                wait=row['wait_days'],
                trend=0
            )
            session.add(hosp)
        session.commit()
    print(f"Loaded {len(df)} hospitals into database.")

if __name__ == "__main__":
    # Path to the data generated by the scraper
    load_hospitals_from_csv("data/waiting_times_latest.csv")
